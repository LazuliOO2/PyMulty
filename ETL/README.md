# ETL Process and Data Dashboard for Mercado Livre Products

## DescriÃ§Ã£o

Este projeto consiste em um processo ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga) para coletar dados de produtos do Mercado Livre e um painel de dashboard para visualizÃ¡-los. O objetivo Ã© fornecer insights sobre preÃ§os, marcas e satisfaÃ§Ã£o do cliente para notebooks.

## Estrutura do Projeto

```

ğŸ“‚ scr
â”œâ”€â”€ ğŸ“„ README.md           â†’ DocumentaÃ§Ã£o principal
â”œâ”€â”€ ğŸ“‚ transform/
â”‚   â””â”€â”€ ğŸ“„ app.ipynb       â†’ Script Jupyter para transformar e carregar os dados
â”œâ”€â”€ ğŸ“‚ mercadolivre/
â”‚   â”œâ”€â”€ ğŸ“„ data.json       â†’ Dados coletados (saÃ­da do Scrapy)
â”‚   â”œâ”€â”€ ğŸ“„ scrapy.cfg      â†’ ConfiguraÃ§Ã£o do Scrapy
â”‚   â”œâ”€â”€ ğŸ“‚ mercadolivre/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ items.py    â†’ DefiniÃ§Ã£o dos itens do Scrapy
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ settings.py â†’ ConfiguraÃ§Ãµes do Scrapy
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ spiders/
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ init.py
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ notebook.py â†’ Spider do Scrapy para coletar dados de notebooks
â”‚   â”‚   â””â”€â”€ ğŸ“„ init.py
â”œâ”€â”€ ğŸ“‚ dashboard/
â”‚   â””â”€â”€ ğŸ“„ app.py          â†’ Script Streamlit para criar o dashboard

```
## Tecnologias Utilizadas

- **Python**: Linguagem de programaÃ§Ã£o principal
- **Scrapy**: Framework para web scraping (coleta de dados)
- **Pandas**: Biblioteca para manipulaÃ§Ã£o e anÃ¡lise de dados
- **SQLAlchemy**: Toolkit SQL para interagir com bancos de dados
- **Streamlit**: Framework para criar aplicativos web interativos
- **MySQL**: Banco de dados para armazenar os dados
- **dotenv**: Biblioteca para carregar variÃ¡veis de ambiente

## InstalaÃ§Ã£o

1.  **Clonar o repositÃ³rio:**

    ```sh
    git clone <URL_DO_REPOSITORIO>
    cd <NOME_DO_REPOSITORIO>
    ```
2.  **Configurar o ambiente virtual (opcional, mas recomendado):**

    ```sh
    python -m venv env
    source env/bin/activate # ou env\Scripts\activate no Windows
    ```
3.  **Instalar as dependÃªncias:**

    ```
    pip install scrapy pandas sqlalchemy python-dotenv streamlit mysql-connector-python
    ```
4.  **Configurar as variÃ¡veis de ambiente:**

    Crie um arquivo `.env` na pasta `scr/transform/` com as credenciais do banco de dados MySQL:

    ```env
    MYSQL_HOST=seu_host
    MYSQL_PORT=3306
    MYSQL_USER=seu_usuario
    MYSQL_PASSWORD=sua_senha
    MYSQL_DATABASE=seu_banco_de_dados
    ```

## ExecuÃ§Ã£o

```
scrapy startproject mercadolivre
```

```
cd mercadolivre
```


```
scrapy genspider notebook mercadolivre.com.br
```

```
scrapy shell
```


```
use fetch('https://lista.mercadolivre.com.br/computadore#D[A:computadore]')
```

```
Defina o user-agent Ã© so pesquisa meu user agent e pegar e copia ou usar inspecionar 
```

```
Agora usamos o comando response para obter os dado que jÃ¡ estÃ£o salvo como response.css('.Mais a class que deseja')
```

```
usamos o comando para salva scrapy crawl notebook -o ../data/data.json
```

## ğŸ“Œ ObservaÃ§Ãµes
Este projeto foi desenvolvido exclusivamente para fins educacionais.
Todos os dados coletados foram utilizados apenas para testes e jÃ¡ foram excluÃ­dos do banco de dados.


## ContribuiÃ§Ã£o

Sinta-se Ã  vontade para contribuir com melhorias, correÃ§Ãµes de bugs ou novas funcionalidades. Basta abrir uma **Pull Request**.

## LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.